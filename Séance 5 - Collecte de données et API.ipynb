{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S√©ance 5 - Collecte de donn√©es et API\n",
    "\n",
    "L'objectif de la s√©ance est de voir un peu de la collecte de donn√©es sur internet, et pour cela de commencer √† se familiariser avec la notion d'API.\n",
    "\n",
    "Quatre moments :\n",
    "- Ce qu'est une API\n",
    "- Une API avec cl√© d'acc√®s : le cas de Twitter\n",
    "- Traiter des donn√©es du web sans API\n",
    "- Quelques notions plus avanc√©es sur les API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment 1 - Ce qu'est une API (Matthias, 30 min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est quoi une API web, les donn√©es sur internet, etc.\n",
    "\n",
    "API : approche tr√®s computer science\n",
    "\n",
    "API, notion g√©n√©rale, et notion orient√©e web sur laquelle nous allons d'abord commencer dans ce cours.\n",
    "\n",
    "API et wrappers; Lien avec les biblioth√®ques\n",
    "\n",
    "-> S3\n",
    "\n",
    "Petit point sur plus g√©n√©ralement la manipulation de donn√©es : Sensibilisation aux limites l√©gales etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques √©l√©ments √† savoir faire :\n",
    "\n",
    "- Rechercher, regarder la documentation, mettre en oeuvre et r√©cup√©rer les donn√©es\n",
    "- V√©rifier l'actualit√© de l'API (ex. de GetOldTweets)\n",
    "- Trois cas rapide : Wikip√©dia & Google Scholar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quelques exemples possibles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wikip√©dia\n",
    "\n",
    "https://pypi.org/project/wikipedia/\n",
    "\n",
    "Les diff√©rents √©l√©ments autour de Python\n",
    "\n",
    "Exemple du fait qu'elle a chang√© entre notre code et la publi du bouquin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### G√©olocalisation avec OSM\n",
    "\n",
    "https://pypi.org/project/geocoder/0.5.7/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[46.5218269, 6.6327025]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geocoder\n",
    "g = geocoder.osm('Lausanne, Suisse')\n",
    "g.latlng"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Scholar\n",
    "\n",
    "Par exemple pour faire de la scientom√©trie\n",
    "\n",
    "https://scholarly.readthedocs.io/en/latest/quickstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scholarly import scholarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Emilien Schultz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the author's data, fill-in, and print\n",
    "search_query = scholarly.search_author('√âmilien Schultz')\n",
    "author = scholarly.fill(next(search_query))\n",
    "print(author['name'])\n",
    "\n",
    "# Print the titles of the author's publications\n",
    "#print([pub['bib']['title'] for pub in author['publications']])\n",
    "\n",
    "# Take a closer look at the first publication\n",
    "#pub = scholarly.fill(author['publications'][0])\n",
    "#print(pub)\n",
    "\n",
    "# Which papers cited that publication?\n",
    "#print([citation['bib']['title'] for citation in scholarly.citedby(pub)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment 2 - Utiliser une API plus complexe : Twitter (Emilien, 30 min)\n",
    "\n",
    "- Tweepy : https://github.com/tweepy/tweepy\n",
    "- Regarder la documentation\n",
    "- l'API Twitter, cr√©er un compte et demander des cr√©dentiels\n",
    "- Mettre ses cr√©dentials\n",
    "- Collecter les tweets r√©cents sur pyshs ?\n",
    "- Collecter les tweets autour d'islamogauchiste sur une p√©riode\n",
    "- Regarder les donn√©es et les mettre en forme\n",
    "- Cr√©er un collecteur qui s'inscrit dans le temps..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un test avec le tutorial de tweepy : les deux √©tapes de configuration de l'API puis son utilisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @isabelapf2: The next Jupyter community call is coming up on Tuesday, May 25th at 8am Pacific. Whether you've been in the community a lo‚Ä¶\n",
      "Pr√©paration de la prochaine s√©ance du cours #pyshs √† Lausanne - les API. Test de l'API :)\n",
      "RT @neuro_rish: @Mbussonn @jeremyphoward @Zoom Jitsi has that feature, love it!\n",
      "ok, @Zoom idea: A pie chart of cumulative  speaker time to _gently_ remind some people that  they monopolize the co‚Ä¶ https://t.co/jc2uktWpIo\n",
      "RT @afs_socio: Annonce importante : notre congr√®s, pr√©vu du 6 au 9 juillet 2021 √† Lille, se tiendra enti√®rement en distanciel. Plus de d√©ta‚Ä¶\n",
      "Bon @UPS_FR il faudrait former vos livreurs au code de la route car √† ma question s'il voyait le probl√®me d'√™tre st‚Ä¶ https://t.co/IunTBaWwE9\n",
      "RT @ADRIPS_comm: #Doctorat\n",
      "#Financement\n",
      "\n",
      "Th√®se (LaPEA, Versailles) : \"Mod√©lisation de l'acceptabilit√© de mesures publiques et d'initiatives‚Ä¶\n",
      "RT @OndrejCertik: My thoughts on the fact that the next version of LAPACK is planned to be implemented in C++ instead of Fortran:\n",
      "\n",
      "https://‚Ä¶\n",
      "RT @Gometmedia: [Urgent] üî¥ üö¥üëè Le 1er dimanche sans voitures √† #Marseille aura lieu le 23 mai sur la #Corniche Un bon d√©but... Roulez, march‚Ä¶\n",
      "RT @katyhuff: Exciting to be part of a slate of such phenomenal appointees announced officially this week @Energy! I was especially happy t‚Ä¶\n",
      "In case you missed it on friday, here is some thoughts and demo on how to improve Scientific Python ecosystem docum‚Ä¶ https://t.co/BdT0NqWces\n",
      "RT @katyhuff: I‚Äôm thrilled to finally share that today is my 1st day in the Department of Energy's Office of Nuclear Energy (@Energy @GovNu‚Ä¶\n",
      "RT @102bis: Ces deux mois de silence sur Twitter, c‚Äô√©tait le temps d‚Äôimaginer avec toute l‚Äô√©quipe d√©missionnaire de #scienceetvie le magazi‚Ä¶\n",
      "√Ä voir : 2e cours de Didier Fassin au Coll√®ge de France, sur \"la\" v√©rit√© des chiffes en sant√© publique. Contre un p‚Ä¶ https://t.co/9c17uSLTYL\n",
      "Et fanfare de pause sur la plaine ouverte https://t.co/tO5iZcJgxM\n",
      "https://t.co/hQ1xBd0DBB\n",
      "https://t.co/MaEqmHpNyP\n",
      "Velorution de Marseille sur le d√©part #criticalmassilia #v√©lorution #marseille #pourquoipaslevelo https://t.co/nwucxjez2x\n",
      "Sidenote which is not in the blog post. This is not specific to Python, I'd love to have something similar for othe‚Ä¶ https://t.co/y9Leq4Gau5\n",
      "RT @ixek: Have you ever wondered what can be done to improve docs in the @ProjectJupyter? Wait no more and  read this blog post by the supe‚Ä¶\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "\n",
    "consumer_key = \"mHqUaZkujRDAAn20gJJAHu3ly\"\n",
    "consumer_secret = \"Iz237BNqXCSStFetp196GwNBXWNTHmmJFit6ZcdxAwwHP17rf0\"\n",
    "access_token = \"1388816341516365825-uQKcLImidWmUhCpNoeVXtftbvDA6tO\"\n",
    "access_token_secret = \"m9ug3cTZIdMAY14ktwd0WXB8ms8HKdijmUMyFnOxWxtKJ\"\n",
    "\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "api = tweepy.API(auth)\n",
    "\n",
    "public_tweets = api.home_timeline()\n",
    "for tweet in public_tweets:\n",
    "    print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poster un tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = api.update_status(\"Pr√©paration de la prochaine s√©ance du cours #pyshs √† Lausanne - les API. Test de l'API :)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mettre le statut √† jour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = api.update_profile(description=\"R√©flexion collective autour de Python pour les Sciences Humaines et Sociales\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Etudier un utilisateur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = api.get_user(\"pyshs\")\n",
    "user.id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R√©cup√©rer tous les tweets mentionnant pyshs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R√©cup√©rer tous les tweets mentionnant islamogauchisme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = api.search(q=\"islamogauchisme\",count=100,lang=\"fr\")\n",
    "len(corpus)\n",
    "#for tweet in corpus:\n",
    "#    print(tweet.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tweepy.models.SearchResults"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [i for i in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'EstelleNasty'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = corpus[1]\n",
    "t.user.screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2021, 5, 15, 12, 28, 20)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Int√©grer ensuite ces donn√©es dans un traitement : par exemple en faire un tableau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "tableau = pd.DataFrame([[t.id_str,t.created_at,i.user.id,i.user.screen_name, i.text,i.user.location] for i in corpus])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Orfeo_Giorgi      3\n",
       "_Attano_          3\n",
       "CestinEric        2\n",
       "divineFrance21    2\n",
       "CarminaRosa19     2\n",
       "                 ..\n",
       "RDD271999019      1\n",
       "lohoudominique    1\n",
       "DelatourRegis     1\n",
       "tonioaa1          1\n",
       "Adlost5           1\n",
       "Name: 3, Length: 91, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tableau[3].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention limite de 7 jours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diff√©rents niveaux d'acc√®s : API premium\n",
    "- https://developer.twitter.com/en/account/environments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = api.search_full_archive(environment_name=\"training\",query=\"islamogauchisme\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pas si facile de se constituer un corpus ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Petite r√©flexion sur la s√©curit√© des donn√©es avec des codes ? Rendre public ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "consumer_key = \"mHqUaZkujRDAAn20gJJAHu3ly\"\n",
    "consumer_secret = \"Iz237BNqXCSStFetp196GwNBXWNTHmmJFit6ZcdxAwwHP17rf0\"\n",
    "access_token = \"1388816341516365825-pQddB13qZxsz3DSHqeKMW8vmHAq2OY\"\n",
    "access_token_secret = \"mSIM8JQwJi3IU1F5MF9bLWRVQIlPzD3d1LHPjCfYu74L3\"\n",
    "\n",
    "codes = {\"consumer_key\":consumer_key,\"consumer_secret\":consumer_secret,\n",
    "         \"access_token\":access_token,\"access_token_secret\":access_token_secret}\n",
    "\n",
    "with open(\"twitter.keys\",\"w\") as f:\n",
    "    json.dump(codes,f)\n",
    "    \n",
    "with open(\"twitter.keys\",\"r\") as f:\n",
    "    codes = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cr√©er une collecte en continue de tweets :\n",
    "- les strat√©gies ?\n",
    "- aller plus loin dans la compr√©hension de Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a donc plusieurs briques qui permettent de cr√©er notre traitement de donn√©es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Des usages plus avanc√©s de l'API : collecter un flux de tweets\n",
    "\n",
    "- un scrit qui fait une veille permanente\n",
    "- doit √™tre ex√©cut√© sur un ordinateur dans la dur√©e (serveur ?)\n",
    "- des √©l√©ments des biblioth√®ques permettant de coder ce type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API initialis√©e\n",
      "1393549207861071875\n",
      "Erreur rencontr√©e\n"
     ]
    }
   ],
   "source": [
    "import tweepy\n",
    "import json\n",
    "\n",
    "# StreamListener class inherits from tweepy.StreamListener and overrides on_status/on_error methods.\n",
    "class StreamListener(tweepy.StreamListener):\n",
    "    def on_status(self, status):\n",
    "        print(status.id_str)\n",
    "        # if \"retweeted_status\" attribute exists, flag this tweet as a retweet.\n",
    "        is_retweet = hasattr(status, \"retweeted_status\")\n",
    "\n",
    "        # check if text has been truncated\n",
    "        if hasattr(status,\"extended_tweet\"):\n",
    "            text = status.extended_tweet[\"full_text\"]\n",
    "        else:\n",
    "            text = status.text\n",
    "\n",
    "        # check if this is a quote tweet.\n",
    "        is_quote = hasattr(status, \"quoted_status\")\n",
    "        quoted_text = \"\"\n",
    "        if is_quote:\n",
    "            # check if quoted tweet's text has been truncated before recording it\n",
    "            if hasattr(status.quoted_status,\"extended_tweet\"):\n",
    "                quoted_text = status.quoted_status.extended_tweet[\"full_text\"]\n",
    "            else:\n",
    "                quoted_text = status.quoted_status.text\n",
    "\n",
    "        # remove characters that might cause problems with csv encoding\n",
    "        remove_characters = [\",\",\"\\n\"]\n",
    "        for c in remove_characters:\n",
    "            text.replace(c,\" \")\n",
    "            quoted_text.replace(c, \" \")\n",
    "            \n",
    "        with open(\"tweets/\"+status.id_str,\"w\") as f:\n",
    "            json.dump(status._json,f)\n",
    "\n",
    "    def on_error(self, status_code):\n",
    "        print(\"Encountered streaming error (\", status_code, \")\")\n",
    "\n",
    "\n",
    "def launch():\n",
    "    try:\n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "        auth.set_access_token(access_token, access_token_secret)\n",
    "        api = tweepy.API(auth)\n",
    "        print(\"API initialis√©e\")\n",
    "        streamListener = StreamListener()\n",
    "        stream = tweepy.Stream(auth=api.auth, listener=streamListener,tweet_mode='extended')\n",
    "        tags = [\"islamogauchisme\"]\n",
    "        stream.filter(track=tags)\n",
    "    except:\n",
    "        print(\"Erreur rencontr√©e\")\n",
    "        #launch()\n",
    "    \n",
    "launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les limites de Tweepy, et la n√©cessit√© de passer par l'API Twitter\n",
    "- https://developer.twitter.com/en/docs/twitter-api/tweets/search/introduction\n",
    "- https://github.com/twitterdev/search-tweets-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment 3 - Pas d'API : collecter directement des donn√©es sur internet (Emilien, 30 min)\n",
    "\n",
    "- Dans certains cas il n'y a pas d'API disponible, r√©cup√©rer directement les donn√©es par les interfaces \"standard\"\n",
    "- Utiliser requests et BeautifulSoup\n",
    "- Importance de la r√©tro-ing√©nieurie : comprendre l'architecture d'une page web\n",
    "- Diff√©rentes strat√©gies : regex ou biblioth√®ques plus avanc√©es\n",
    "- R√©cup√©rer des images ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R√©cup√©rer des notices de livres Python sur Wordcat https://www.worldcat.org/ puis mettre en forme dans un fichier\n",
    "- chercher islamo-gauchisme\n",
    "- voir la forme de l'URL https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=21&qt=page_number_link\n",
    "\n",
    "D√©marche : \n",
    "- r√©cup√©rer les pages de r√©sultat\n",
    "- construire un tableau des liens vers les r√©sultats\n",
    "- r√©cup√©rer chaque notice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Premi√®re √©tape regarder un peu les √©l√©ments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### R√©cup√©rer une page avec requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "url = \"https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=1&qt=page_number_link\"\n",
    "\n",
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toutes les pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=1&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=11&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=21&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=31&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=41&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=51&qt=page_number_link\n",
      "https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start=61&qt=page_number_link\n"
     ]
    }
   ],
   "source": [
    "pages = []\n",
    "for i in range(0,7):\n",
    "    url = \"https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start={}&qt=page_number_link\".format(1+10*i)\n",
    "    print(url)\n",
    "    page = requests.get(url)\n",
    "    pages.append(page)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extraire les liens : un peu de r√©troing√©nierie\n",
    "\n",
    "Plusieurs strat√©gies :\n",
    "- tous les liens et filtrer\n",
    "- respecter la structure du document"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Se balader dans la structure html : BeautifoulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = bs4.BeautifulSoup(pages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "liens = page.find_all(\"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "liens = [i.attrs[\"href\"] for i in liens if \"href\" in i.attrs and \"/oclc/\" in i.attrs[\"href\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'/title/allons-nous-sortir-de-lhistoire/oclc/1100451295',\n",
       " '/title/emirats-de-la-republique-comment-les-islamistes-prennent-possession-de-la-banlieue/oclc/1140404936',\n",
       " '/title/empoisonneurs-antisemitisme-islamophobie-xenophobie/oclc/1198222296',\n",
       " '/title/islamo-gauchisme/oclc/8760612072',\n",
       " '/title/islamo-gauchisme/oclc/8932537540',\n",
       " '/title/liaisons-dangereuses-islamo-nazisme-islamo-gauchisme/oclc/1248694509',\n",
       " '/title/livre-des-indesires-une-histoire-des-arabes-en-france/oclc/1084514701',\n",
       " '/title/negationnisme-de-gauche/oclc/1099928429',\n",
       " '/title/racines-de-lislamo-gauchisme-dossier/oclc/1057453730',\n",
       " '/title/racisme-imaginaire-islamophobie-et-culpabilite/oclc/974816801'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([i.replace(\"&referer=brief_results\",\"\").replace(\"/editions?editionsView=true&referer=br\",\"\") for i in liens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = liens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.attrs[\"href\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecrire une fonction pour r√©cup√©rer les √©l√©ments dont on a besoin sur chacune des pages ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.worldcat.org/title/islamo-gauchisme-du-pseudo-debat-a-la-realite-du-terrain/oclc/8999871764\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = bs4.BeautifulSoup(requests.get(url).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "details = page.find_all(\"div\",{\"id\":\"details\"})[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume = details.find_all(\"div\",{\"class\":\"abstracttxt\"})[0].text\n",
    "doctype =  details.find_all(\"tr\",{\"id\":\"details-doctype\"})[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(url):\n",
    "    page = bs4.BeautifulSoup(requests.get(url).content)\n",
    "    details = page.find_all(\"div\",{\"id\":\"details\"})[0]\n",
    "    resume = details.find_all(\"div\",{\"class\":\"abstracttxt\"})[0].text\n",
    "    doctype =  details.find_all(\"tr\",{\"id\":\"details-doctype\"})[0].text\n",
    "    return [url,resume,doctype]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.worldcat.org/title/islamo-gauchisme-du-pseudo-debat-a-la-realite-du-terrain/oclc/8999871764',\n",
       " \"\\n           Au c≈ìur de ce deÃÅbat qui prend des tournures toujours plus inattendues, j'ai eu la chance d'avoir une conversation exigeante et mesureÃÅe, afin de prendre un peu de recul. Merci aÃÄ CTRL Z pour sa confiance et, au passage, pour ses articles d'une trop rare finesse sur le mondes numeÃÅriques et les deÃÅbats de notre temps ! La conversation meneÃÅe avec la mirifique Elodie Safaris est accessible sur Youtube ou Spotify ; je vous incruste ici la version Youtube. https://www.youtube.com/embed/ausj14hU-e...\",\n",
       " '\\nDocument Type:\\nArticle\\n']"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www.worldcat.org/title/islamo-gauchisme-du-pseudo-debat-a-la-realite-du-terrain/oclc/8999871764\"\n",
    "get_info(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tout int√©grer dans un script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for i in range(0,7):\n",
    "    url = \"https://www.worldcat.org/search?q=islamo-gauchisme&fq=&dblist=638&start={}&qt=page_number_link\".format(1+10*i)\n",
    "    page = requests.get(url)\n",
    "    page = bs4.BeautifulSoup(page.content)\n",
    "    liens = page.find_all(\"a\")\n",
    "    liens = [i.attrs[\"href\"] for i in liens if \"href\" in i.attrs and \"/oclc/\" in i.attrs[\"href\"]]\n",
    "    liens = set([i.replace(\"&referer=brief_results\",\"\").replace(\"/editions?editionsView=true&referer=br\",\"\") for i in liens])\n",
    "    corpus+=list(liens)\n",
    "\n",
    "data = []\n",
    "for url in corpus:\n",
    "    data.append(get_info(url))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Moment 4 - Plus d'API, du point de vue humain √† celui de l'ordinateur (Matthias, 15-30 min)\n",
    "\n",
    "Diff√©rents types d'API / G√©n√©ralisation\n",
    "\n",
    "Diff√©rentes version d'API\n",
    "\n",
    "Normalisation\n",
    "\n",
    "REST/ GraphQL\n",
    "\n",
    "usages plus compliqu√©s : async\n",
    "\n",
    "Cr√©er sa propre API ? Garder la signature des fonctions\n",
    "\n",
    "API non web\n",
    "\n",
    "Poster\n",
    "\n",
    "- Livres Gallica : https://api.bnf.fr/fr/wrapper-python-pour-les-api-gallica / https://github.com/ian-nai/PyGallica\n",
    "- Vid√©os : https://pypi.org/project/python-youtube/\n",
    "- Scrapper plus complexes (scrapy, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
